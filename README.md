# ðŸ§  GAN-Powered Face Image Generation (128Ã—128 Resolution)

This project demonstrates a **Generative Adversarial Network (GAN)** built using **TensorFlow** and **Keras**, capable of generating realistic human face images at a resolution of 128Ã—128 pixels. The model learns to convert random noise vectors into detailed, symmetric facial images. After training for **105 epochs**, it produces visually compelling outputs with natural textures and structure.

<img width="721" height="662" alt="Screenshot 2025-07-27 at 11 32 15â€¯PM" src="https://github.com/user-attachments/assets/be7a1e4c-9507-470e-9747-cf841e8e41ad" />

---
```
#ðŸ“‚ GAN-Face-Generator/
â”œâ”€â”€ main.py # Generates sample outputs using the trained model
â”œâ”€â”€ main.ipynb # Model building and training logic (Generator + Discriminator)
â”œâ”€â”€ requirements.txt # List of required Python packages
â”œâ”€â”€ .gitignore # Ignores virtual environments, checkpoints, caches, etc.
â””â”€â”€ README.md # Project overview and documentation
```
----
## ðŸ“¦ Installation & Dependencies

To set up the environment, install the required packages: `requirements.txt`:

```bash
pip install -r requirements.txt
```
Core Libraries Used:
	â€¢	tensorflow
	â€¢	numpy
	â€¢	matplotlib
	â€¢	tqdm
	â€¢	time, os (standard libraries)

# ðŸ§  Model Architecture

Generator (Upsampling: 100-dim â†’ 128Ã—128Ã—3)
- Dense(8Ã—8Ã—512) â†’ Reshape â†’ BatchNorm â†’ LeakyReLU
- Conv2DTranspose: 256 â†’ 128 â†’ 64 â†’ 32 â†’ 3
- Final activation: tanh (outputs in [-1, 1])

Discriminator (Downsampling: 128Ã—128Ã—3 â†’ binary output)
- Conv2D: 64 â†’ 128 â†’ 256 â†’ 512
- LeakyReLU + Dropout after each layer
- Flatten â†’ Dense(1) logit output

## ðŸ§ª Training Strategy

The models were trained adversarially using a custom training loop in TensorFlow:
```python
#Loss Functions:
#Binary crossentropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def discriminator_loss(real_output, fake_output):
    return cross_entropy(tf.ones_like(real_output), real_output) + \
           cross_entropy(tf.zeros_like(fake_output), fake_output)

# Training Step:
def train_step(real_images):
    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])
    ...
    g_loss = generator_loss(fake_output)
    d_loss = discriminator_loss(real_output, fake_output)
    ...
    # Apply gradients to both networks
    
# Optimizers:

gen_optimizer = tf.keras.optimizers.Adam(1e-4)
disc_optimizer = tf.keras.optimizers.Adam(1e-4)
```
```txt
# ðŸ“ˆ Training Configuration
PParameter            | Value
---------------------|----------------------
Dataset              | CelebA
Noise Input          | 100-dimensional
Image Output         | 128Ã—128 RGB
Epochs               | 105
Batch Size           | 128 (customizable)
Loss Function        | Binary Crossentropy
Optimizer            | Adam (learning rate = 1e-4)
Framework            | TensorFlow 2.16.2
```
# ðŸ™Œ Acknowledgements
	â€¢	Ian Goodfellow et al., GAN Paper (2014)
	â€¢	TensorFlow & Keras Teams
	â€¢	CelebA Dataset


